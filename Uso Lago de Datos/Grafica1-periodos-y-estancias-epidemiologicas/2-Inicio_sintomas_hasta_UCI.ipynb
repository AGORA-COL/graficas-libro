{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7f3bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, datediff, when, avg, row_number\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4095a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .appName(\"onset_icu\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f40a8",
   "metadata": {},
   "source": [
    "## Cargar base SEGCOVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(archivo, columnas):\n",
    "    try:\n",
    "        return spark.read.parquet(archivo).select(*columnas)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {archivo}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006036df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_segcovid = {\n",
    "    \"df_2020\": \"hdfs:///rawdata/segcovid/segcovid_parquet_2020\",\n",
    "    \"df_2021\": \"hdfs:///rawdata/segcovid/segcovid_parquet_2021\",\n",
    "    \"df_2022\": \"hdfs:///rawdata/segcovid/segcovid_parquet_2022\",\n",
    "    \"df_2023\": \"hdfs:///rawdata/segcovid/segcovid_parquet_2023\"\n",
    "}\n",
    "\n",
    "# Columnas de interés\n",
    "columnas_segcovid = [\"PersonaBasicaID\", \n",
    "                     \"AmbitoAtencion\", \n",
    "                     \"FechaIngresoAtencion\",\n",
    "                     \"DepartamentoAtencion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298cecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todos los DataFrames\n",
    "dfs_segcovid = []\n",
    "for nombre, archivo in dir_segcovid.items():\n",
    "    df = cargar_datos(archivo, columnas_segcovid)\n",
    "    if df is not None:\n",
    "        dfs_segcovid.append(df)\n",
    "\n",
    "# Concatenar\n",
    "if dfs_segcovid:\n",
    "    df_segcovid = dfs_segcovid[0]\n",
    "    for df in dfs_segcovid[1:]:\n",
    "        df_segcovid = df_segcovid.unionByName(df, allowMissingColumns=True)\n",
    "        \n",
    "    # SEGCOVID filtrada por Cuidado Intensivo y Bogotá\n",
    "    df_icu = df_segcovid.filter(col(\"AmbitoAtencion\") == \"Cuidado Intensivo\")\n",
    "    df_icu = df_icu.filter(col(\"DepartamentoAtencion\") == \"11 - Bogotá D.C.\").drop_duplicates().persist()\n",
    "\n",
    "else:\n",
    "    df_segcovid = None\n",
    "    df_icu = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo es la estructura de la base\n",
    "total_registros = df_icu.count()\n",
    "ids_unicos = df_icu.select('PersonaBasicaID').distinct().count()\n",
    "print(f\"Total de registros en df_icu: {total_registros}\")\n",
    "print(f\"Total de columnas en df_icu: {len(df_icu.columns)}\")\n",
    "print(f\"Número de ids únicos en df_icu: {ids_unicos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe538f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista con los IDs únicos de personas que estuvieron en UCI de acuerdo a SEGCOVID\n",
    "ids_list = df_icu.select(\"PersonaBasicaID\").distinct().rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ead52f",
   "metadata": {},
   "source": [
    "## Cargar base SIVIGILA346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a71e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sivigila346 = pd.read_csv(\"../Github/dl-covid19-descriptive-reports/MinSalud/sivigila346/data/ExtraccionEv346.txt\",\n",
    "                             low_memory=False,\n",
    "                             on_bad_lines='skip',\n",
    "                             sep='|',\n",
    "                             usecols = ['PersonaBasicaID',\n",
    "                                        'FechaNotificacion',\n",
    "                                        'FechaInicioSintomas',\n",
    "                                        'DepartamentoNotificacion'])\n",
    "\n",
    "print('Número filas y columnas: ', df_sivigila346.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11356bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros basura (son 2)\n",
    "df_sivigila346 = df_sivigila346.dropna(subset=['FechaInicioSintomas'])\n",
    "print('Número filas y columnas: ', df_sivigila346.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c665e2e",
   "metadata": {},
   "source": [
    "## Análisis para Bogotá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los datos de Bogotá\n",
    "df_bog = df_sivigila346[df_sivigila346['DepartamentoNotificacion'] == 'Bogotá, D.C.'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las fechas a formato 'datetime'\n",
    "df_bog['FechaInicioSintomas'] = pd.to_datetime(df_bog['FechaInicioSintomas'].astype(int), format='%Y%m%d')\n",
    "df_bog['FechaNotificacion'] = pd.to_datetime(df_bog['FechaNotificacion'].astype(int), format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c031fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar fechas de inicio de síntomas erróneas\n",
    "df_bog = df_bog[df_bog['FechaInicioSintomas'] != '19000101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Descartar los casos donde el ID es igual a 1\n",
    "# ============================================\n",
    "df_bog = df_bog[df_bog['PersonaBasicaID'] != '1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb80034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionad IDs únicos\n",
    "df_bog_filtrado = df_bog[df_bog[\"PersonaBasicaID\"].isin(ids_list)].copy()\n",
    "\n",
    "# Convertir base a df de pySpark\n",
    "df_sivigila_spark = spark.createDataFrame(df_bog_filtrado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8bb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo es la estructura de la base\n",
    "total_registros = df_sivigila_spark.count()\n",
    "ids_unicos = df_sivigila_spark.select('PersonaBasicaID').distinct().count()\n",
    "print(f\"Total de registros en df_sivigila_spark: {total_registros}\")\n",
    "print(f\"Total de columnas en df_sivigila_spark: {len(df_sivigila_spark.columns)}\")\n",
    "print(f\"Número de ids únicos en df_sivigila_spark: {ids_unicos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52507005",
   "metadata": {},
   "source": [
    "## Cruce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb97be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas de fecha a tipo fecha en Spark\n",
    "df_icu = df_icu.withColumn(\"FechaIngresoAtencion\", to_date(col(\"FechaIngresoAtencion\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaInicioSintomas\", to_date(col(\"FechaInicioSintomas\"), \"yyyy-MM-dd\"))\n",
    "df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaNotificacion\", to_date(col(\"FechaNotificacion\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb30d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir por PersonaBasicaID\n",
    "df_join = df_icu.join(df_sivigila_spark, on=\"PersonaBasicaID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo es la estructura de la base\n",
    "total_registros = df_join.count()\n",
    "ids_unicos = df_join.select('PersonaBasicaID').distinct().count()\n",
    "print(f\"Total de registros en df_join: {total_registros}\")\n",
    "print(f\"Total de columnas en df_join: {len(df_join.columns)}\")\n",
    "print(f\"Número de ids únicos en df_join: {ids_unicos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc816e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33f584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b8b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ee176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e5f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b8f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde02da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar registros donde FechaIngresoAtencion >= FechaInicioSintomas\n",
    "df_join2 = df_join.filter(F.col(\"FechaIngresoAtencion\") >= F.col(\"FechaInicioSintomas\"))\n",
    "\n",
    "# Calcular la diferencia de días \"Onset_icu\"\n",
    "df_join2 = df_join2.withColumn(\"Onset_icu\", datediff(col(\"FechaIngresoAtencion\"), col(\"FechaInicioSintomas\")))\n",
    "\n",
    "# Definir la ventana particionada por PersonaBasicaID y FechaInicioSintomas, ordenando por \"Onset_icu\"\n",
    "window_Onset_icu = Window.partitionBy(\"PersonaBasicaID\", \"FechaInicioSintomas\").orderBy(\"Onset_icu\")\n",
    "\n",
    "# Asignar un número de fila en cada partición\n",
    "df_con_rn = df_join2.withColumn(\"rn\", F.row_number().over(window_Onset_icu))\n",
    "\n",
    "# Seleccionar la fila con rn = 1 (la de menor diferencia) y eliminar la columna auxiliar\n",
    "df_con_onset = df_con_rn.filter(F.col(\"rn\") == 1).drop(\"rn\", \"AmbitoAtencion\", \"DepartamentoNotificacion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_rn.select(\"PersonaBasicaID\", \"FechaIngresoAtencion\", \"FechaNotificacion\", \"FechaInicioSintomas\", \"Onset_icu\", \"rn\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c07870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_onset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo es la estructura de la base\n",
    "total_registros = df_con_onset.count()\n",
    "ids_unicos = df_con_onset.select('PersonaBasicaID').distinct().count()\n",
    "print(f\"Total de registros en df_con_onset: {total_registros}\")\n",
    "print(f\"Total de columnas en df_con_onset: {len(df_con_onset.columns)}\")\n",
    "print(f\"Número de ids únicos en df_con_onset: {ids_unicos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f265c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las olas de COVID-19\n",
    "# Crear columna de ola\n",
    "expr_ola = when(col(\"FechaInicioSintomas\").between(\"2020-02-26\", \"2020-09-25\"), \"Ola_1\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2020-11-01\", \"2021-03-01\"), \"Ola_2\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2021-03-01\", \"2021-09-14\"), \"Ola_3\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2021-11-20\", \"2022-03-24\"), \"Ola_4\") \\\n",
    "          .otherwise(\"Fuera_Ola\")\n",
    "\n",
    "# Omitiendo la primera ola\n",
    "# expr_ola = when(col(\"FechaInicioSintomas\").between(\"2020-11-01\", \"2021-03-01\"), \"Ola_2\") \\\n",
    "#     .when(col(\"FechaInicioSintomas\").between(\"2021-03-01\", \"2021-09-14\"), \"Ola_3\") \\\n",
    "#     .when(col(\"FechaInicioSintomas\").between(\"2021-11-20\", \"2022-03-24\"), \"Ola_4\") \\\n",
    "#     .otherwise(\"Fuera_Ola\")\n",
    "\n",
    "df_para_olas = df_con_onset.withColumn(\"Ola_COVID\", expr_ola)\n",
    "df_para_olas = df_para_olas.filter((col(\"Ola_COVID\") != 'Fuera_Ola'))\n",
    "\n",
    "# ##########$%&\"%#$#$#$$$$\"\n",
    "# # FILTROS\n",
    "df_para_olas = df_para_olas[df_para_olas['Onset_icu'] >= 0]\n",
    "df_para_olas = df_para_olas[df_para_olas['Onset_icu'] <= 100]\n",
    "\n",
    "# Contar el número de casos por ola\n",
    "df_avg = df_para_olas.groupBy(\"Ola_COVID\").agg(avg(\"Onset_icu\").alias(\"AVG_Onset_icu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09187531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_olas.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18872377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados \n",
    "df_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "proms = df_avg.sort(\"Ola_COVID\").select('AVG_Onset_icu').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54b890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "promedios = proms\n",
    "promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedios.insert(0, np.nan)\n",
    "# promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a4d62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "waves = ['Wave 1', 'Wave 2', 'Wave 3', 'Wave 4']\n",
    "colors = ['#6b6ca3', '#87bcbd', '#6f9954', '#b1615c']\n",
    "\n",
    "# Crear figura\n",
    "plt.figure(figsize=(4, 5))\n",
    "\n",
    "# Graficar barras, ignorando las NaN\n",
    "for i, (wave, promedio, color) in enumerate(zip(waves, promedios, colors)):\n",
    "    if not np.isnan(promedio):\n",
    "        # Dibuja la barra normal si hay datos\n",
    "        plt.bar(wave, promedio, color=color, width=1.0)\n",
    "        plt.text(i, promedio + 0.2, f'{promedio:.2f}', ha='center', fontsize=9)\n",
    "    else:\n",
    "        # Dibuja una barra con patrón (o sin relleno) para marcar la falta de datos\n",
    "        plt.bar(wave, 0, color='none', edgecolor=color, width=1.0, hatch='//')\n",
    "        # Coloca el texto indicando la insuficiencia de datos\n",
    "        plt.text(i, 0.9, 'There is not', ha='center', fontsize=7.5, color='#6b6ca3')\n",
    "        plt.text(i, 0.2, 'enough data', ha='center', fontsize=7.5, color='#6b6ca3')\n",
    "\n",
    "# Etiquetas\n",
    "# plt.xlabel('COVID-19 waves')\n",
    "plt.ylabel('Avg value of delay time (Days)', fontsize=14)\n",
    "plt.title('Onset to ICU Bogotá')\n",
    "plt.yticks([0.0, 2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5])\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef32fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_olas.groupBy(\"Ola_COVID\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671e2ac",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213ec942",
   "metadata": {},
   "source": [
    "## Análisis Nacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, to_date, datediff, when, row_number, avg\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Filtrar SEGCOVID para \"Cuidado Intensivo\" (sin filtrar por departamento aún)\n",
    "df_icu_global = df_segcovid.filter(col(\"AmbitoAtencion\") == \"Cuidado Intensivo\") \\\n",
    "                           .drop_duplicates() \\\n",
    "                           .persist()\n",
    "\n",
    "# Diccionario para almacenar resultados finales\n",
    "resultados = {}\n",
    "\n",
    "# Definir las condiciones para asignar la ola de COVID (según FechaInicioSintomas)\n",
    "expr_ola = when(col(\"FechaInicioSintomas\").between(\"2020-02-26\", \"2020-09-25\"), \"Ola_1\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2020-11-01\", \"2021-03-01\"), \"Ola_2\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2021-03-01\", \"2021-09-14\"), \"Ola_3\") \\\n",
    "          .when(col(\"FechaInicioSintomas\").between(\"2021-11-20\", \"2022-03-24\"), \"Ola_4\") \\\n",
    "          .otherwise(\"Fuera_Ola\")\n",
    "\n",
    "df_icu_dep = df_icu_global.drop_duplicates() \\\n",
    "                          .persist()\n",
    "\n",
    "# Crear la lista de IDs únicos de personas en UCI para el departamento\n",
    "ids_list_dep = df_icu_dep.select(\"PersonaBasicaID\").distinct() \\\n",
    "                         .rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Filtrar los datos de Sivigila para el departamento actual (usando DepartamentoNotificacion)\n",
    "df_col = df_sivigila346.copy()\n",
    "\n",
    "# Convertir las fechas a formato datetime en Pandas\n",
    "df_col['FechaInicioSintomas'] = pd.to_datetime(df_col['FechaInicioSintomas'].astype(int), format='%Y%m%d')\n",
    "df_col['FechaNotificacion'] = pd.to_datetime(df_col['FechaNotificacion'].astype(int), format='%Y%m%d')\n",
    "\n",
    "# Eliminar fechas erróneas y registros no válidos\n",
    "df_col = df_col[df_col['FechaInicioSintomas'] != '19000101']\n",
    "df_col = df_col[df_col['PersonaBasicaID'] != '1']\n",
    "\n",
    "# Filtrar para que solo queden los IDs que estuvieron en UCI\n",
    "df_dep_filtrado = df_col[df_col[\"PersonaBasicaID\"].isin(ids_list_dep)].copy()\n",
    "\n",
    "# Convertir el DataFrame filtrado de Pandas a DataFrame de PySpark\n",
    "df_sivigila_spark = spark.createDataFrame(df_dep_filtrado)\n",
    "\n",
    "# Convertir las columnas de fecha a tipo date en Spark\n",
    "df_icu_dep = df_icu_dep.withColumn(\"FechaIngresoAtencion\", to_date(col(\"FechaIngresoAtencion\"), \"yyyy-MM-dd\"))\n",
    "df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaInicioSintomas\", to_date(col(\"FechaInicioSintomas\"), \"yyyy-MM-dd\"))\n",
    "df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaNotificacion\", to_date(col(\"FechaNotificacion\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Unir ambas fuentes por PersonaBasicaID\n",
    "df_join = df_icu_dep.join(df_sivigila_spark, on=\"PersonaBasicaID\", how=\"inner\")\n",
    "\n",
    "# Filtrar registros donde FechaIngresoAtencion >= FechaInicioSintomas\n",
    "df_join2 = df_join.filter(col(\"FechaIngresoAtencion\") >= col(\"FechaInicioSintomas\"))\n",
    "\n",
    "# Calcular la diferencia en días entre la fecha de ingreso y el inicio de síntomas\n",
    "df_join2 = df_join2.withColumn(\"Onset_icu\", datediff(col(\"FechaIngresoAtencion\"), col(\"FechaInicioSintomas\")))\n",
    "\n",
    "# Usar ventana para quedarse con el registro de menor diferencia por PersonaBasicaID y FechaInicioSintomas\n",
    "window_Onset_icu = Window.partitionBy(\"PersonaBasicaID\", \"FechaInicioSintomas\").orderBy(\"Onset_icu\")\n",
    "df_con_rn = df_join2.withColumn(\"rn\", row_number().over(window_Onset_icu))\n",
    "df_con_onset = df_con_rn.filter(col(\"rn\") == 1) \\\n",
    "                        .drop(\"rn\", \"AmbitoAtencion\", \"DepartamentoNotificacion\")\n",
    "\n",
    "# Asignar la ola correspondiente a cada registro\n",
    "df_para_olas = df_con_onset.withColumn(\"Ola_COVID\", expr_ola)\n",
    "df_para_olas = df_para_olas.filter((col(\"Ola_COVID\") != 'Fuera_Ola'))\n",
    "\n",
    "# Aplicar filtros para considerar Onset_icu entre 0 y 100 días\n",
    "df_para_olas = df_para_olas.filter((col(\"Onset_icu\") >= 0) & (col(\"Onset_icu\") <= 100))\n",
    "\n",
    "# Calcular el promedio de Onset_icu por cada ola\n",
    "df_avg = df_para_olas.groupBy(\"Ola_COVID\").agg(avg(\"Onset_icu\").alias(\"AVG_Onset_icu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b903708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados \n",
    "df_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061e40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "proms = df_avg.sort(\"Ola_COVID\").select('AVG_Onset_icu').rdd.flatMap(lambda x: x).collect()\n",
    "promedios = proms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f21935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedios.insert(0, np.nan)\n",
    "# promedios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = ['Ola 1', 'Ola 2', 'Ola 3', 'Ola 4']\n",
    "colors = ['#6a5acd', '#66c2a5', '#4daf4a', '#d95f02']\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "for i, (wave, promedio, color) in enumerate(zip(waves, promedios, colors)):\n",
    "    if not np.isnan(promedio):\n",
    "        plt.bar(wave, promedio, color=color, width=0.7, zorder=3)\n",
    "        plt.text(i, promedio + 0.2, f'{promedio:.1f}', ha='center', fontsize=9)\n",
    "    else:\n",
    "        plt.bar(wave, 0, color='none', edgecolor=color, width=1.0, hatch='//')\n",
    "\n",
    "        plt.text(i, 0.9, 'There is not', ha='center', fontsize=7.5, color='#6b6ca3')\n",
    "        plt.text(i, 0.2, 'enough data', ha='center', fontsize=7.5, color='#6b6ca3')\n",
    "\n",
    "# Etiquetas\n",
    "# plt.xlabel('COVID-19 waves')\n",
    "plt.ylabel('Promedio (días)', fontsize=12)\n",
    "plt.title('Inicio de síntomas hasta UCI', fontsize=14)\n",
    "plt.yticks([0, 5, 10, 15, 20, 25], fontsize=10)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.6, zorder=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe4618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_olas.groupBy(\"Ola_COVID\").count().sort(\"Ola_COVID\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6dfae",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Análisis para todos los departamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55727f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sivigila346_v2 = df_sivigila346[df_sivigila346['DepartamentoNotificacion'] != 'NO REPORTADO'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66709532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://dgn.isolutions.iso.org/obp/ui#iso:code:3166:CO\n",
    "df_sivigila346_v2['DepartamentoNotificacion'].replace({'Bogotá, D.C.': 'DC', \n",
    "                                                       'Antioquia': 'ANT', \n",
    "                                                       'Valle del Cauca': 'VAC', \n",
    "                                                       'Cundinamarca': 'CUN', \n",
    "                                                       'Santander': 'SAN', \n",
    "                                                       'Atlántico': 'ATL', \n",
    "                                                       'Boyacá': 'BOY', \n",
    "                                                       'Norte de Santander': 'NSA', \n",
    "                                                       'Córdoba': 'COR', \n",
    "                                                       'Tolima': 'TOL', \n",
    "                                                       'Caldas': 'CAL', \n",
    "                                                       'Cesar': 'CES', \n",
    "                                                       'Meta': 'MET', \n",
    "                                                       'Risaralda': 'RIS', \n",
    "                                                       'Huila': 'HUI', \n",
    "                                                       'Bolívar': 'BOL', \n",
    "                                                       'Cauca': 'CAU', \n",
    "                                                       'Sucre': 'SUC', \n",
    "                                                       'Quindio': 'QUI', \n",
    "                                                       'Nariño': 'NAR', \n",
    "                                                       'Magdalena': 'MAG', \n",
    "                                                       'Casanare': 'CAS', \n",
    "                                                       'La Guajira': 'LAG', \n",
    "                                                       'Caquetá': 'CAQ', \n",
    "                                                       'Putumayo': 'PUT', \n",
    "                                                       'Chocó': 'CHO', \n",
    "                                                       'Arauca': 'ARA', \n",
    "                                                       'Archipiélago de San Andrés, Providencia y Santa Catalina': 'SAP', \n",
    "                                                       'Amazonas': 'AMA', \n",
    "                                                       'Guaviare': 'GUV', \n",
    "                                                       'Guainía': 'GUA', \n",
    "                                                       'Vichada': 'VIC', \n",
    "                                                       'Vaupés': 'VAU'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1753dcb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, to_date, datediff, when, row_number, avg\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Cargar y unir los DataFrames de SEGCOVID\n",
    "dfs_segcovid = []\n",
    "for nombre, archivo in dir_segcovid.items():\n",
    "    df = cargar_datos(archivo, columnas_segcovid)\n",
    "    if df is not None:\n",
    "        dfs_segcovid.append(df)\n",
    "\n",
    "if dfs_segcovid:\n",
    "    df_segcovid = dfs_segcovid[0]\n",
    "    for df in dfs_segcovid[1:]:\n",
    "        df_segcovid = df_segcovid.unionByName(df, allowMissingColumns=True)\n",
    "else:\n",
    "    df_segcovid = None\n",
    "\n",
    "df_segcovid = df_segcovid.filter(col(\"DepartamentoAtencion\") != \"-1 - NO DEFINIDO\")\n",
    "\n",
    "df_segcovid_v2 = df_segcovid.withColumn(\n",
    "    'DepartamentoAtencion',\n",
    "     when(df_segcovid['DepartamentoAtencion'] == '11 - Bogotá D.C.', 'DC')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '05 - Antioquia', 'ANT')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '76 - Valle del Cauca', 'VAC')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '08 - Atlántico', 'ATL')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '25 - Cundinamarca', 'CUN')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '68 - Santander', 'SAN')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '13 - Bolívar', 'BOL')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '47 - Magdalena', 'MAG')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '15 - Boyacá', 'BOY')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '17 - Caldas', 'CAL')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '52 - Nariño', 'NAR')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '20 - Cesar', 'CES')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '23 - Córdoba', 'COR')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '73 - Tolima', 'TOL')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '50 - Meta', 'MET')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '41 - Huila', 'HUI')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '54 - Norte de Santander', 'NSA')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '66 - Risaralda', 'RIS')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '19 - Cauca', 'CAU')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '44 - La Guajira', 'LAG')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '70 - Sucre', 'SUC')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '63 - Quindio', 'QUI')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '85 - Casanare', 'CAS')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '18 - Caquetá', 'CAQ')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '86 - Putumayo', 'PUT')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '27 - Chocó', 'CHO')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '81 - Arauca', 'ARA')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '91 - Amazonas', 'AMA')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '88 - Archipiélago de San Andrés Providencia y Santa Catalina', 'SAP')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '95 - Guaviare', 'GUV')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '99 - Vichada', 'VIC')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '94 - Guainía', 'GUA')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '97 - Vaupés', 'VAU')\n",
    "    .otherwise(df_segcovid['DepartamentoAtencion'])\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Filtrar SEGCOVID para \"Cuidado Intensivo\" (sin filtrar por departamento aún)\n",
    "df_icu_global = df_segcovid_v2.filter(col(\"AmbitoAtencion\") == \"Cuidado Intensivo\") \\\n",
    "                           .drop_duplicates() \\\n",
    "                           .persist()\n",
    "\n",
    "# Obtener la lista única de departamentos (columna DepartamentoAtencion)\n",
    "departamentos = [row[0] for row in df_segcovid_v2.select(\"DepartamentoAtencion\").distinct().collect()]\n",
    "\n",
    "# Lista para almacenar resultados finales\n",
    "results = []\n",
    "conteos = []\n",
    "\n",
    "# Definir las condiciones para asignar la ola de COVID (según FechaInicioSintomas)\n",
    "expr_ola = when(col(\"FechaInicioSintomas\").between(\"2020-02-26\", \"2020-09-25\"), \"Wave 1\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2020-11-01\", \"2021-03-01\"), \"Wave 2\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2021-03-01\", \"2021-09-14\"), \"Wave 3\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2021-11-20\", \"2022-03-24\"), \"Wave 4\") \\\n",
    "           .otherwise(\"Fuera_Ola\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Iterar sobre cada departamento\n",
    "for dept in departamentos:\n",
    "    # Filtrar df_icu para el departamento actual\n",
    "    df_icu_dep = df_icu_global.filter(col(\"DepartamentoAtencion\") == dept) \\\n",
    "                              .drop_duplicates() \\\n",
    "                              .persist()\n",
    "    \n",
    "    # Crear la lista de IDs únicos de personas en UCI para el departamento\n",
    "    ids_list_dep = df_icu_dep.select(\"PersonaBasicaID\").distinct() \\\n",
    "                             .rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    # Filtrar los datos de Sivigila para el departamento actual (usando DepartamentoNotificacion)\n",
    "    df_dep = df_sivigila346_v2[df_sivigila346_v2['DepartamentoNotificacion'] == dept].copy()\n",
    "    \n",
    "    # Convertir las fechas a formato datetime en Pandas\n",
    "    df_dep['FechaInicioSintomas'] = pd.to_datetime(df_dep['FechaInicioSintomas'].astype(int), format='%Y%m%d')\n",
    "    df_dep['FechaNotificacion'] = pd.to_datetime(df_dep['FechaNotificacion'].astype(int), format='%Y%m%d')\n",
    "    \n",
    "    # Eliminar fechas erróneas y registros no válidos\n",
    "    df_dep = df_dep[df_dep['FechaInicioSintomas'] != '19000101']\n",
    "    df_dep = df_dep[df_dep['PersonaBasicaID'] != '1']\n",
    "    \n",
    "    # Filtrar para que solo queden los IDs que estuvieron en UCI\n",
    "    df_dep_filtrado = df_dep[df_dep[\"PersonaBasicaID\"].isin(ids_list_dep)].copy()\n",
    "    \n",
    "    if len(df_dep_filtrado) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Convertir el DataFrame filtrado de Pandas a DataFrame de PySpark\n",
    "    df_sivigila_spark = spark.createDataFrame(df_dep_filtrado)\n",
    "    \n",
    "    # Convertir las columnas de fecha a tipo date en Spark\n",
    "    df_icu_dep = df_icu_dep.withColumn(\"FechaIngresoAtencion\", to_date(col(\"FechaIngresoAtencion\"), \"yyyy-MM-dd\"))\n",
    "    df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaInicioSintomas\", to_date(col(\"FechaInicioSintomas\"), \"yyyy-MM-dd\"))\n",
    "    df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaNotificacion\", to_date(col(\"FechaNotificacion\"), \"yyyy-MM-dd\"))\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 4. Unir ambas fuentes por PersonaBasicaID\n",
    "    df_join = df_icu_dep.join(df_sivigila_spark, on=\"PersonaBasicaID\", how=\"inner\")\n",
    "    \n",
    "    # Filtrar registros donde FechaIngresoAtencion >= FechaInicioSintomas\n",
    "    df_join2 = df_join.filter(col(\"FechaIngresoAtencion\") >= col(\"FechaInicioSintomas\"))\n",
    "    \n",
    "    # Calcular la diferencia en días entre la fecha de ingreso y el inicio de síntomas\n",
    "    df_join2 = df_join2.withColumn(\"Onset_icu\", datediff(col(\"FechaIngresoAtencion\"), col(\"FechaInicioSintomas\")))\n",
    "    \n",
    "    # Usar ventana para quedarse con el registro de menor diferencia por PersonaBasicaID y FechaInicioSintomas\n",
    "    window_Onset_icu = Window.partitionBy(\"PersonaBasicaID\", \"FechaInicioSintomas\").orderBy(\"Onset_icu\")\n",
    "    df_con_rn = df_join2.withColumn(\"rn\", row_number().over(window_Onset_icu))\n",
    "    df_con_onset = df_con_rn.filter(col(\"rn\") == 1) \\\n",
    "                            .drop(\"rn\", \"AmbitoAtencion\", \"DepartamentoNotificacion\")\n",
    "    \n",
    "    # Asignar la ola correspondiente a cada registro\n",
    "    df_para_olas = df_con_onset.withColumn(\"Ola_COVID\", expr_ola)\n",
    "    df_para_olas = df_para_olas.filter((col(\"Ola_COVID\") != 'Fuera_Ola'))\n",
    "    \n",
    "    # Aplicar filtros para considerar Onset_icu entre 0 y 100 días\n",
    "    df_para_olas = df_para_olas.filter((col(\"Onset_icu\") >= 0) & (col(\"Onset_icu\") <= 100))\n",
    "    \n",
    "    # Calcular el promedio de Onset_icu por cada ola\n",
    "    df_avg = df_para_olas.groupBy(\"Ola_COVID\").agg(avg(\"Onset_icu\").alias(\"AVG_Onset_icu\")).sort(\"Ola_COVID\")\n",
    "   \n",
    "    # Guardar en el diccionario final usando el departamento como clave\n",
    "    for row in df_avg.collect():\n",
    "        results.append({\n",
    "            'Departamento': dept,\n",
    "            'Wave': row[\"Ola_COVID\"],\n",
    "            'MeanDelay': row[\"AVG_Onset_icu\"]\n",
    "        })\n",
    "        \n",
    "    for row in df_para_olas.groupBy(\"Ola_COVID\").count().sort(\"Ola_COVID\").collect():\n",
    "        conteos.append({\n",
    "            'Departamento': dept,\n",
    "            'Wave': row[\"Ola_COVID\"],\n",
    "            'Registros': row[\"count\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc876308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "pivot_table = df_results.pivot(index=\"Departamento\", columns=\"Wave\", values=\"MeanDelay\")\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dfb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conteos = pd.DataFrame(conteos)\n",
    "tabla_conteos = df_conteos.pivot(index=\"Departamento\", columns=\"Wave\", values=\"Registros\")\n",
    "tabla_conteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef71cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica heatmap\n",
    "plt.figure(figsize=(3, len(pivot_table)*0.25)) \n",
    "sns.heatmap(pivot_table, \n",
    "            annot=True, \n",
    "            cmap=\"coolwarm\", #RdYlGr coolwarm summer\n",
    "            fmt=\".2f\",\n",
    "            annot_kws={\"size\": 8})\n",
    "plt.title(\"Avg Delay from \\nOnset to ICU\", fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Department\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443af4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x='Wave', y='MeanDelay', data=df_results, palette=\"Set3\", hue='Wave', legend=False, showfliers=False)\n",
    "sns.swarmplot(x='Wave', y='MeanDelay', data=df_results, color=\".25\")\n",
    "plt.title(\"Onset to ICU\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Avg value of delay time (Days)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53555d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab6ef04c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "## Análisis para todos los departamentos POR REGIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sivigila346_v2 = df_sivigila346[df_sivigila346['DepartamentoNotificacion'] != 'NO REPORTADO'].copy()\n",
    "\n",
    "# https://dgn.isolutions.iso.org/obp/ui#iso:code:3166:CO\n",
    "df_sivigila346_v2['DepartamentoNotificacion'].replace({'Bogotá, D.C.': 'DC', \n",
    "                                                       'Antioquia': 'ANT', \n",
    "                                                       'Valle del Cauca': 'VAC', \n",
    "                                                       'Cundinamarca': 'CUN', \n",
    "                                                       'Santander': 'SAN', \n",
    "                                                       'Atlántico': 'ATL', \n",
    "                                                       'Boyacá': 'BOY', \n",
    "                                                       'Norte de Santander': 'NSA', \n",
    "                                                       'Córdoba': 'COR', \n",
    "                                                       'Tolima': 'TOL', \n",
    "                                                       'Caldas': 'CAL', \n",
    "                                                       'Cesar': 'CES', \n",
    "                                                       'Meta': 'MET', \n",
    "                                                       'Risaralda': 'RIS', \n",
    "                                                       'Huila': 'HUI', \n",
    "                                                       'Bolívar': 'BOL', \n",
    "                                                       'Cauca': 'CAU', \n",
    "                                                       'Sucre': 'SUC', \n",
    "                                                       'Quindio': 'QUI', \n",
    "                                                       'Nariño': 'NAR', \n",
    "                                                       'Magdalena': 'MAG', \n",
    "                                                       'Casanare': 'CAS', \n",
    "                                                       'La Guajira': 'LAG', \n",
    "                                                       'Caquetá': 'CAQ', \n",
    "                                                       'Putumayo': 'PUT', \n",
    "                                                       'Chocó': 'CHO', \n",
    "                                                       'Arauca': 'ARA', \n",
    "                                                       'Archipiélago de San Andrés, Providencia y Santa Catalina': 'SAP', \n",
    "                                                       'Amazonas': 'AMA', \n",
    "                                                       'Guaviare': 'GUV', \n",
    "                                                       'Guainía': 'GUA', \n",
    "                                                       'Vichada': 'VIC', \n",
    "                                                       'Vaupés': 'VAU'}, inplace=True)\n",
    "\n",
    "def classify_region(department):\n",
    "    region_map = {\n",
    "        \"Amazónica\": [\"AMA\", \"CAQ\", \"GUA\", \"GUV\", \"PUT\", \"VAU\"],\n",
    "        \"Andina\": [\"ANT\", \"BOY\", \"CAL\", \"CUN\", \"DC\", \"HUI\", \"NSA\", \"QUI\", \"RIS\", \"SAN\", \"TOL\"],\n",
    "        \"Pacífica\": [\"VAC\", \"CHO\", \"CAU\", \"NAR\"],\n",
    "        \"Caribe e Insular\": [\"ATL\", \"BOL\", \"CES\", \"COR\", \"LAG\", \"MAG\", \"SUC\", \"SAP\"],\n",
    "        \"Orinoquía\": [\"ARA\", \"CAS\", \"MET\", \"VIC\"]\n",
    "    }\n",
    "    \n",
    "    for region, departments in region_map.items():\n",
    "        if department in departments:\n",
    "            return region\n",
    "    return \"Desconocido\"  # En caso de que haya códigos no contemplados\n",
    "\n",
    "# Aplicar la función a la columna DepartamentoNotificacion\n",
    "df_sivigila346_v2[\"Region\"] = df_sivigila346_v2[\"DepartamentoNotificacion\"].apply(classify_region)\n",
    "\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, to_date, datediff, when, row_number, avg\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Cargar y unir los DataFrames de SEGCOVID\n",
    "dfs_segcovid = []\n",
    "for nombre, archivo in dir_segcovid.items():\n",
    "    df = cargar_datos(archivo, columnas_segcovid)\n",
    "    if df is not None:\n",
    "        dfs_segcovid.append(df)\n",
    "\n",
    "if dfs_segcovid:\n",
    "    df_segcovid = dfs_segcovid[0]\n",
    "    for df in dfs_segcovid[1:]:\n",
    "        df_segcovid = df_segcovid.unionByName(df, allowMissingColumns=True)\n",
    "else:\n",
    "    df_segcovid = None\n",
    "\n",
    "df_segcovid = df_segcovid.filter(col(\"DepartamentoAtencion\") != \"-1 - NO DEFINIDO\")\n",
    "\n",
    "df_segcovid_v2 = df_segcovid.withColumn(\n",
    "    'DepartamentoAtencion',\n",
    "     when(df_segcovid['DepartamentoAtencion'] == '11 - Bogotá D.C.', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '05 - Antioquia', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '76 - Valle del Cauca', 'Pacífica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '08 - Atlántico', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '25 - Cundinamarca', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '68 - Santander', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '13 - Bolívar', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '47 - Magdalena', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '15 - Boyacá', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '17 - Caldas', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '52 - Nariño', 'Pacífica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '20 - Cesar', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '23 - Córdoba', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '73 - Tolima', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '50 - Meta', 'Orinoquía')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '41 - Huila', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '54 - Norte de Santander', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '66 - Risaralda', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '19 - Cauca', 'Pacífica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '44 - La Guajira', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '70 - Sucre', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '63 - Quindio', 'Andina')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '85 - Casanare', 'Orinoquía')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '18 - Caquetá', 'Amazónica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '86 - Putumayo', 'Amazónica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '27 - Chocó', 'Pacífica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '81 - Arauca', 'Orinoquía')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '91 - Amazonas', 'Amazónica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '88 - Archipiélago de San Andrés Providencia y Santa Catalina', 'Caribe e Insular')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '95 - Guaviare', 'Amazónica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '99 - Vichada', 'Orinoquía')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '94 - Guainía', 'Amazónica')\n",
    "    .when(df_segcovid['DepartamentoAtencion'] == '97 - Vaupés', 'Amazónica')\n",
    "    .otherwise(df_segcovid['DepartamentoAtencion'])\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Filtrar SEGCOVID para \"Cuidado Intensivo\" (sin filtrar por departamento aún)\n",
    "df_icu_global = df_segcovid_v2.filter(col(\"AmbitoAtencion\") == \"Cuidado Intensivo\") \\\n",
    "                           .drop_duplicates() \\\n",
    "                           .persist()\n",
    "\n",
    "# Obtener la lista única de departamentos (columna DepartamentoAtencion)\n",
    "departamentos = [row[0] for row in df_segcovid_v2.select(\"DepartamentoAtencion\").distinct().collect()]\n",
    "\n",
    "# Lista para almacenar resultados finales\n",
    "results = []\n",
    "conteos = []\n",
    "\n",
    "# Definir las condiciones para asignar la ola de COVID (según FechaInicioSintomas)\n",
    "expr_ola = when(col(\"FechaInicioSintomas\").between(\"2020-02-26\", \"2020-09-25\"), \"Wave 1\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2020-11-01\", \"2021-03-01\"), \"Wave 2\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2021-03-01\", \"2021-09-14\"), \"Wave 3\") \\\n",
    "           .when(col(\"FechaInicioSintomas\").between(\"2021-11-20\", \"2022-03-24\"), \"Wave 4\") \\\n",
    "           .otherwise(\"Fuera_Ola\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Iterar sobre cada departamento\n",
    "for dept in departamentos:\n",
    "    # Filtrar df_icu para el departamento actual\n",
    "    df_icu_dep = df_icu_global.filter(col(\"DepartamentoAtencion\") == dept) \\\n",
    "                              .drop_duplicates() \\\n",
    "                              .persist()\n",
    "    \n",
    "    # Crear la lista de IDs únicos de personas en UCI para el departamento\n",
    "    ids_list_dep = df_icu_dep.select(\"PersonaBasicaID\").distinct() \\\n",
    "                             .rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    # Filtrar los datos de Sivigila para el departamento actual (usando DepartamentoNotificacion)\n",
    "    df_dep = df_sivigila346_v2[df_sivigila346_v2['Region'] == dept].copy()\n",
    "    \n",
    "    # Convertir las fechas a formato datetime en Pandas\n",
    "    df_dep['FechaInicioSintomas'] = pd.to_datetime(df_dep['FechaInicioSintomas'].astype(int), format='%Y%m%d')\n",
    "    df_dep['FechaNotificacion'] = pd.to_datetime(df_dep['FechaNotificacion'].astype(int), format='%Y%m%d')\n",
    "    \n",
    "    # Eliminar fechas erróneas y registros no válidos\n",
    "    df_dep = df_dep[df_dep['FechaInicioSintomas'] != '19000101']\n",
    "    df_dep = df_dep[df_dep['PersonaBasicaID'] != '1']\n",
    "    \n",
    "    # Filtrar para que solo queden los IDs que estuvieron en UCI\n",
    "    df_dep_filtrado = df_dep[df_dep[\"PersonaBasicaID\"].isin(ids_list_dep)].copy()\n",
    "    \n",
    "    if len(df_dep_filtrado) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Convertir el DataFrame filtrado de Pandas a DataFrame de PySpark\n",
    "    df_sivigila_spark = spark.createDataFrame(df_dep_filtrado)\n",
    "    \n",
    "    # Convertir las columnas de fecha a tipo date en Spark\n",
    "    df_icu_dep = df_icu_dep.withColumn(\"FechaIngresoAtencion\", to_date(col(\"FechaIngresoAtencion\"), \"yyyy-MM-dd\"))\n",
    "    df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaInicioSintomas\", to_date(col(\"FechaInicioSintomas\"), \"yyyy-MM-dd\"))\n",
    "    df_sivigila_spark = df_sivigila_spark.withColumn(\"FechaNotificacion\", to_date(col(\"FechaNotificacion\"), \"yyyy-MM-dd\"))\n",
    "    \n",
    "    # -------------------------------\n",
    "    # 4. Unir ambas fuentes por PersonaBasicaID\n",
    "    df_join = df_icu_dep.join(df_sivigila_spark, on=\"PersonaBasicaID\", how=\"inner\")\n",
    "    \n",
    "    # Filtrar registros donde FechaIngresoAtencion >= FechaInicioSintomas\n",
    "    df_join2 = df_join.filter(col(\"FechaIngresoAtencion\") >= col(\"FechaInicioSintomas\"))\n",
    "    \n",
    "    # Calcular la diferencia en días entre la fecha de ingreso y el inicio de síntomas\n",
    "    df_join2 = df_join2.withColumn(\"Onset_icu\", datediff(col(\"FechaIngresoAtencion\"), col(\"FechaInicioSintomas\")))\n",
    "    \n",
    "    # Usar ventana para quedarse con el registro de menor diferencia por PersonaBasicaID y FechaInicioSintomas\n",
    "    window_Onset_icu = Window.partitionBy(\"PersonaBasicaID\", \"FechaInicioSintomas\").orderBy(\"Onset_icu\")\n",
    "    df_con_rn = df_join2.withColumn(\"rn\", row_number().over(window_Onset_icu))\n",
    "    df_con_onset = df_con_rn.filter(col(\"rn\") == 1) \\\n",
    "                            .drop(\"rn\", \"AmbitoAtencion\", \"DepartamentoNotificacion\", \"Region\")\n",
    "    \n",
    "    # Asignar la ola correspondiente a cada registro\n",
    "    df_para_olas = df_con_onset.withColumn(\"Ola_COVID\", expr_ola)\n",
    "    df_para_olas = df_para_olas.filter((col(\"Ola_COVID\") != 'Fuera_Ola'))\n",
    "    \n",
    "    # Aplicar filtros para considerar Onset_icu entre 0 y 100 días\n",
    "    df_para_olas = df_para_olas.filter((col(\"Onset_icu\") >= 0) & (col(\"Onset_icu\") <= 100))\n",
    "    \n",
    "    # Calcular el promedio de Onset_icu por cada ola\n",
    "    df_avg = df_para_olas.groupBy(\"Ola_COVID\").agg(avg(\"Onset_icu\").alias(\"AVG_Onset_icu\")).sort(\"Ola_COVID\")\n",
    "    print(df_avg.show())\n",
    "    \n",
    "    # Guardar en el diccionario final usando el departamento como clave\n",
    "    for row in df_avg.collect():\n",
    "        results.append({\n",
    "            'Region': dept,\n",
    "            'Wave': row[\"Ola_COVID\"],\n",
    "            'MeanDelay': row[\"AVG_Onset_icu\"]\n",
    "        })\n",
    "    for row in df_para_olas.groupBy(\"Ola_COVID\").count().sort(\"Ola_COVID\").collect():\n",
    "        conteos.append({\n",
    "            'Region': dept,\n",
    "            'Wave': row[\"Ola_COVID\"],\n",
    "            'Registros': row[\"count\"]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56058ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "pivot_table = df_results.pivot(index=\"Region\", columns=\"Wave\", values=\"MeanDelay\")\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188b17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conteos = pd.DataFrame(conteos)\n",
    "tabla_conteos = df_conteos.pivot(index=\"Region\", columns=\"Wave\", values=\"Registros\")\n",
    "tabla_conteos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica heatmap\n",
    "plt.figure(figsize=(4, 3.5)) \n",
    "sns.heatmap(pivot_table, \n",
    "            annot=True, \n",
    "            cmap=\"coolwarm\", #RdYlGr coolwarm summer\n",
    "            fmt=\".2f\",\n",
    "            annot_kws={\"size\": 9})\n",
    "plt.title(\"Avg Delay from \\nOnset to ICU\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Crear líneas para cada departamento\n",
    "for reg in pivot_table.index:\n",
    "    plt.plot(pivot_table.columns, pivot_table.loc[reg], marker='o', linestyle='-', label=reg)\n",
    "\n",
    "plt.title(\"Onset to ICU entrance\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel('Avg value of delay time (Days)', fontsize=12)\n",
    "plt.legend(title=\"Region\", loc='upper right', fontsize=9, bbox_to_anchor=(1.34, 1.02)) \n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acc4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "num_regions = len(pivot_table)\n",
    "num_waves = len(pivot_table.columns)\n",
    "\n",
    "x = np.arange(num_regions)\n",
    "width = 0.15  \n",
    "\n",
    "# Barras\n",
    "colors = ['#6b6ca3', '#87bcbd', '#6f9954', '#b1615c']\n",
    "for i, wave in enumerate(pivot_table.columns):\n",
    "    plt.bar(x + i * width, pivot_table[wave], width=width, label=wave, color=colors[i])\n",
    "\n",
    "plt.xticks(x + width * (num_waves / 2 - 0.5), pivot_table.index, rotation=0, fontsize=9)\n",
    "plt.ylabel('Avg value of delay time (Days)')\n",
    "plt.title(\"Onset to ICU entrance\")\n",
    "plt.legend(title=\"COVID-19 Wave\", fontsize=9, bbox_to_anchor=(1.25, 1.02))\n",
    "plt.yticks([0, 2.5, 5.0, 7.5, 10.0, 12.5, 15.0, 17.5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1507b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce142175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
